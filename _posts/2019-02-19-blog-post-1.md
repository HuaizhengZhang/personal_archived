---
title: '[Paper reading]: Deep Learning Inference in Facebook Data Centers: Characterization, Performance Optimizations and Hardware Implications
date: 2019-02-19
permalink: /posts/2019/02/blog-post-1/
tags:
  - Paper
  - System
  - Deep Learning
---

### What is the problem that is being solved?

This is a review paper which shows the new trend in Facebook data center.
The new trend is that there are higher deep learning (DL) inference demand with a steady improvement in 
both size and quality of models. These models often require more computation and memory resource which need to be optimized.
As the pace of changes in DL models is very fast, the previous optimization for old models may not suitable for new models.

This paper presents a characterizations of DL models and then shows the new trend for DL hardware design:

- High memory bandwidth and capacity for embeddings
- Support for powerful matrix and vector engines
- Large on-chip memory for inference with small batches
- Support for half-precision floating-point computation

### What are the metrics of success?

Review paper has no metrics of success. There are some good metric can be used in system papers.

- Model Type
- Model Size
- Batch Size
- Max Live activations
- Arith. intensity (weights)
- Arith. intensity (act. & weights)
- Latency (constraints)

### What are the key innovations over prior work?

- Speeding up the embedding look ups is very important.

- For system optimizations, it is better to monitor the performance of DL models continuously. 

- To estimate the benefits of optimizing any specific operator, it is very useful to implement the observer software design pattern.
The observer can track the performance metrics for each operator's execution. 

### What are the key results?

For a recommendation system, the the overall model's execution tends to be memory bandwidth bound and is dominated by the embedding look ups.

### What are some of the limitations and how might this work be improved?

Review paper. No

### How might this work have long term impact?

This work shares the experience of how to better co-design hardware to support current and future DL models in Facebook

The experience must guide a lot of papers or projects that focus on machine learning system design to follow. 
